import { useEffect, useRef, useState, type JSX, useCallback } from 'react';
import { useParams } from 'react-router-dom';
import type { TeleconsultaData } from '../types/interfaces';
import { Layout } from '../components/Layout';

// =========================================================================================
// 1. IMPORTA√á√ïES DO MEDIAPIPE
// =========================================================================================
import { FilesetResolver, PoseLandmarker } from '@mediapipe/tasks-vision';
   
// =========================================================================================
// 2. TIPOS E INTERFACES
// =========================================================================================

type PostureFeedback = {
  message: string;
  status: 'ideal' | 'warning' | 'error' | 'loading';
};

// =========================================================================================
// 3. L√ìGICA DE AN√ÅLISE DE POSTURA COM MEDIAPIPE
// =========================================================================================

const analyzePostureFromLandmarks = (landmarks: any[]): PostureFeedback => {
  if (!landmarks || landmarks.length === 0) {
    return {
      message: "üîç Nenhuma pessoa detectada. Certifique-se de estar vis√≠vel na c√¢mera.",
      status: 'warning'
    };
  }

  // Exemplo de an√°lise simplificada baseada em landmarks
  // Landmarks importantes: 0-nariz, 11-ombro esquerdo, 12-ombro direito, 23-24 quadril
  const nose = landmarks[0];
  const leftShoulder = landmarks[11];
  const rightShoulder = landmarks[12];
  
  // Calcular dist√¢ncia entre ombros para verificar enquadramento
  const shoulderDistance = Math.sqrt(
    Math.pow(leftShoulder.x - rightShoulder.x, 2) + 
    Math.pow(leftShoulder.y - rightShoulder.y, 2)
  );

  // Calcular posi√ß√£o vertical do nariz (para verificar se est√° centralizado)
  const noseVerticalPosition = nose.y;

  // L√≥gica de an√°lise baseada nas coordenadas
  if (shoulderDistance < 0.2) {
    return {
      message: "‚ö†Ô∏è Por favor, afaste-se um pouco mais para enquadrar o corpo superior.",
      status: 'warning'
    };
  } else if (shoulderDistance > 0.4) {
    return {
      message: "‚ö†Ô∏è Muito pr√≥ximo! Recue um pouco para melhor enquadramento.",
      status: 'warning'
    };
  } else if (noseVerticalPosition < 0.3 || noseVerticalPosition > 0.7) {
    return {
      message: "üìè Ajuste a posi√ß√£o: mantenha o rosto mais centralizado na tela.",
      status: 'warning'
    };
  } else {
    return {
      message: "‚úÖ Posi√ß√£o Ideal! Rosto e tronco bem enquadrados.",
      status: 'ideal'
    };
  }
};

// Fallback para quando o MediaPipe n√£o est√° dispon√≠vel
const analyzePostureFallback = (): PostureFeedback => {
  const now = Date.now();
  const cycle = now % 20000;

  if (cycle < 5000) {
    return {
      message: "‚úÖ Posi√ß√£o Ideal! Rosto e tronco bem enquadrados.",
      status: 'ideal'
    };
  } else if (cycle < 10000) {
    return {
      message: "‚ö†Ô∏è Por favor, afaste-se um pouco mais para enquadrar o corpo superior.",
      status: 'warning'
    };
  } else if (cycle < 15000) {
    return {
      message: "‚ùå Postura Inadequada. Mantenha os ombros vis√≠veis e evite inclinar-se.",
      status: 'error'
    };
  } else {
    return {
      message: "Aguardando detec√ß√£o de postura...",
      status: 'loading'
    };
  }
};

// Componente para exibir o painel de feedback
const FeedbackPanel = ({ feedback, patientName }: { feedback: PostureFeedback, patientName: string }) => {
  let bgColor, borderColor, icon;
 
  switch (feedback.status) {
    case 'ideal':
      bgColor = 'bg-green-50';
      borderColor = 'border-green-500';
      icon = '‚úÖ';
      break;
    case 'warning':
      bgColor = 'bg-yellow-50';
      borderColor = 'border-yellow-500';
      icon = '‚ö†Ô∏è';
      break;
    case 'error':
      bgColor = 'bg-red-50';
      borderColor = 'border-red-500';
      icon = '‚ùå';
      break;
    case 'loading':
    default:
      bgColor = 'bg-blue-50';
      borderColor = 'border-blue-500';
      icon = 'üîÑ';
      break;
  }

  return (
    <div className={`p-6 rounded-xl shadow-xl border-l-4 ${bgColor} ${borderColor} h-full space-y-4`}>
      <h3 className="text-xl font-bold text-gray-800">Orienta√ß√µes de Postura</h3>
      <p className="text-sm text-gray-600">
        Ajuste sua posi√ß√£o na c√¢mera, {patientName}, para garantir que o m√©dico tenha a melhor visibilidade durante a consulta.
      </p>
     
      <div className={`p-4 rounded-lg font-semibold text-lg border ${
        feedback.status === 'ideal' ? 'bg-green-100 border-green-600 text-green-800' : 
        feedback.status === 'warning' ? 'bg-yellow-100 border-yellow-600 text-yellow-800' :
        feedback.status === 'error' ? 'bg-red-100 border-red-600 text-red-800' :
        'bg-white border-gray-300 text-gray-700'
      }`}>
        {icon} {feedback.message}
      </div>

      <p className="text-xs text-gray-500 pt-2">O sistema monitora em tempo real a posi√ß√£o do seu corpo e rosto.</p>
    </div>
  );
};

// =========================================================================================
// 4. COMPONENTE PRINCIPAL
// =========================================================================================

export function Teleconsulta(): JSX.Element {
  const { consultaId } = useParams<{ consultaId: string }>();
  const [teleconsulta, setTeleconsulta] = useState<TeleconsultaData | null>(null);
  const [feedback, setFeedback] = useState<PostureFeedback>({ 
    message: "Iniciando c√¢mera e modelo de IA...", 
    status: 'loading' 
  });
  const [cameraError, setCameraError] = useState<string | null>(null);
  const [mediaPipeStatus, setMediaPipeStatus] = useState<'loading' | 'ready' | 'error'>('loading');

  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationFrameRef = useRef<number | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);
  const lastAnalysisTimeRef = useRef<number>(0);
  const analysisInterval = 100; // Analisar a cada 100ms para resposta r√°pida

  // =========================================================================================
  // INICIALIZA√á√ÉO DO MEDIAPIPE
  // =========================================================================================
  const initializeMediaPipe = useCallback(async () => {
    try {
      setMediaPipeStatus('loading');
      setFeedback({ message: "Carregando modelo de detec√ß√£o corporal...", status: 'loading' });

      console.log('Inicializando MediaPipe...');
      
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );

      console.log('FilesetResolver carregado, criando PoseLandmarker...');

      poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numPoses: 1
      });

      console.log('PoseLandmarker inicializado com sucesso!');
      setMediaPipeStatus('ready');
      setFeedback({ message: "Modelo carregado! Iniciando an√°lise...", status: 'loading' });

    } catch (error) {
      console.error('Erro ao inicializar MediaPipe:', error);
      setMediaPipeStatus('error');
      setFeedback({ 
        message: "‚ö†Ô∏è Modo simula√ß√£o ativado (IA n√£o dispon√≠vel)", 
        status: 'warning' 
      });
    }
  }, []);

  // =========================================================================================
  // DETEC√á√ÉO DE POSTURA COM MEDIAPIPE
  // =========================================================================================
  const detectPosture = useCallback((timestamp: number) => {
    if (!videoRef.current || videoRef.current.readyState < 2) {
      animationFrameRef.current = requestAnimationFrame(detectPosture);
      return;
    }

    // Throttling para performance
    if (timestamp - lastAnalysisTimeRef.current < analysisInterval) {
      animationFrameRef.current = requestAnimationFrame(detectPosture);
      return;
    }

    lastAnalysisTimeRef.current = timestamp;

    try {
      // Usar MediaPipe se estiver dispon√≠vel
      if (poseLandmarkerRef.current && mediaPipeStatus === 'ready') {
        poseLandmarkerRef.current.detectForVideo(videoRef.current, timestamp, (result) => {
          if (result.landmarks && result.landmarks.length > 0) {
            const newFeedback = analyzePostureFromLandmarks(result.landmarks[0]);
            setFeedback(newFeedback);
          } else {
            // Nenhuma pessoa detectada
            setFeedback({
              message: "üîç Nenhuma pessoa detectada. Certifique-se de estar vis√≠vel na c√¢mera.",
              status: 'warning'
            });
          }
        });
      } else {
        // Fallback para an√°lise simulada
        const newFeedback = analyzePostureFallback();
        setFeedback(newFeedback);
      }
    } catch (error) {
      console.error('Erro na detec√ß√£o:', error);
      // Fallback em caso de erro
      const newFeedback = analyzePostureFallback();
      setFeedback(newFeedback);
    }

    animationFrameRef.current = requestAnimationFrame(detectPosture);
  }, [mediaPipeStatus]);

  // =========================================================================================
  // INICIALIZA√á√ÉO DA C√ÇMERA
  // =========================================================================================
  const startWebcam = useCallback(async () => {
    try {
      // Cleanup anterior
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }

      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      console.log('Solicitando acesso √† c√¢mera...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: { ideal: 640 },
          height: { ideal: 480 },
          frameRate: { ideal: 30 }
        }, 
        audio: true 
      });
      
      streamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        
        // Esperar o v√≠deo estar pronto
        const waitForVideo = () => {
          if (videoRef.current && videoRef.current.readyState >= 2) {
            console.log('V√≠deo pronto, iniciando detec√ß√£o...');
            setCameraError(null);
            lastAnalysisTimeRef.current = performance.now();
            animationFrameRef.current = requestAnimationFrame(detectPosture);
          } else {
            setTimeout(waitForVideo, 100);
          }
        };
        
        waitForVideo();
      }
    } catch (err) {
      console.error("Erro ao acessar c√¢mera:", err);
      const errorMessage = "‚ùå N√£o foi poss√≠vel acessar a c√¢mera. Verifique as permiss√µes.";
      setFeedback({
        message: errorMessage,
        status: 'error'
      });
      setCameraError(errorMessage);
    }
  }, [detectPosture]);

  // =========================================================================================
  // EFFECT PRINCIPAL
  // =========================================================================================
  useEffect(() => {
    // Carregar dados da teleconsulta
    const fetchedData: TeleconsultaData = {
      id: consultaId || '1',
      patientName: "Jo√£o da Silva",
      patientAge: 75,
    };
    setTeleconsulta(fetchedData);

    // Inicializar MediaPipe e depois a c√¢mera
    const initializeAll = async () => {
      await initializeMediaPipe();
      await startWebcam();
    };

    initializeAll();

    // Cleanup completo
    return () => {
      console.log('Fazendo cleanup...');
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      
      if (videoRef.current) {
        videoRef.current.srcObject = null;
      }
      
      // Limpar MediaPipe
      poseLandmarkerRef.current = null;
    };
  }, [consultaId, initializeMediaPipe, startWebcam]);

  // =========================================================================================
  // FUN√á√ÉO PARA REINICIAR
  // =========================================================================================
  const restartCamera = async () => {
    setFeedback({ message: "Reiniciando c√¢mera...", status: 'loading' });
    setCameraError(null);
    await startWebcam();
  };

  const restartMediaPipe = async () => {
    setFeedback({ message: "Reiniciando modelo de IA...", status: 'loading' });
    await initializeMediaPipe();
  };

  if (!teleconsulta) {
    return (
      <Layout>
        <div className="text-center py-12">Carregando informa√ß√µes da teleconsulta...</div>
      </Layout>
    );
  }

  return (
    <Layout>
      <div className="min-h-screen bg-gray-50 font-sans p-4 sm:p-6 lg:p-8">
        <div className="max-w-7xl mx-auto">
          <h1 className="text-3xl font-extrabold text-indigo-800 text-center mb-8 border-b pb-4">
            Teleconsulta: {teleconsulta.patientName} ({teleconsulta.patientAge} anos)
          </h1>
        </div>

        <div className="flex flex-col lg:flex-row gap-8 max-w-7xl mx-auto min-h-[600px]">
         
          {/* COLUNA 1: Tela de V√≠deo */}
          <div className="lg:flex-2 flex-1 bg-gray-800 rounded-2xl shadow-2xl relative overflow-hidden min-h-[400px]">
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="w-full h-full object-cover rounded-2xl transform scale-x-[-1]"
            />
           
            <canvas ref={canvasRef} className="hidden" />

            {/* Overlay com informa√ß√£o b√°sica */}
            <div className="absolute bottom-4 left-4 p-2 px-4 bg-indigo-600 bg-opacity-80 text-white rounded-lg font-medium text-sm shadow-lg">
              <p>Sua C√¢mera Ativa</p>
              <p className="text-xs opacity-75">
                {mediaPipeStatus === 'ready' ? 'ü§ñ IA Ativa' : 
                 mediaPipeStatus === 'loading' ? 'üîÑ Carregando IA...' : '‚ö†Ô∏è Modo Simula√ß√£o'}
              </p>
            </div>
           
            {/* Feedback flutuante em caso de erro */}
            {cameraError && (
              <div className="absolute inset-0 bg-black bg-opacity-70 flex items-center justify-center p-4">
                <div className="bg-white rounded-lg p-6 text-center max-w-md">
                  <p className="font-semibold text-red-600 mb-4">{cameraError}</p>
                  <button 
                    onClick={restartCamera}
                    className="px-6 py-2 bg-indigo-600 hover:bg-indigo-700 text-white rounded-lg transition-colors font-medium"
                  >
                    Tentar Novamente
                  </button>
                </div>
              </div>
            )}

            {/* Indicador de status */}
            {!cameraError && feedback.status === 'loading' && (
              <div className="absolute top-4 right-4 p-2 bg-black bg-opacity-50 text-white rounded-lg text-sm">
                {mediaPipeStatus === 'loading' ? 'üîÑ Carregando IA...' : 'üîç Analisando...'}
              </div>
            )}
          </div>

          {/* COLUNA 2: Painel de Feedback e Orienta√ß√£o */}
          <div className="lg:flex-1 w-full lg:w-1/3">
            <FeedbackPanel
              feedback={feedback}
              patientName={teleconsulta.patientName.split(' ')[0] || "paciente"}
            />
            
            {/* Bot√µes de controle */}
            <div className="mt-4 flex gap-2 flex-wrap">
              <button 
                onClick={restartCamera}
                className="flex-1 px-4 py-2 bg-gray-200 hover:bg-gray-300 text-gray-800 rounded-lg transition-colors font-medium"
              >
                üîÑ C√¢mera
              </button>
              <button 
                onClick={restartMediaPipe}
                className="flex-1 px-4 py-2 bg-blue-200 hover:bg-blue-300 text-blue-800 rounded-lg transition-colors font-medium"
              >
                {mediaPipeStatus === 'ready' ? 'üîÑ IA' : 'ü§ñ IA'}
              </button>
            </div>

            {/* Status do sistema */}
            <div className="mt-4 p-3 bg-gray-100 rounded-lg text-xs text-gray-600">
              <p><strong>Status:</strong> {
                mediaPipeStatus === 'ready' ? 'IA funcionando normalmente' :
                mediaPipeStatus === 'loading' ? 'Carregando modelo de IA...' :
                'Usando an√°lise simulada'
              }</p>
              {cameraError && <p className="text-red-600 mt-1">{cameraError}</p>}
            </div>
          </div>
        </div>
      </div>
    </Layout>
  );
}