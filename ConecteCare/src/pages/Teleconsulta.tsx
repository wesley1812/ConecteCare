import { useEffect, useRef, useState, useCallback } from 'react';

// =========================================================================================
// 1. CONFIGURA√á√ÉO MEDIAPIPE E DEPEND√äNCIAS
// Nota: Em um ambiente de projeto real, @mediapipe/tasks-vision deve estar instalado.
// Para este exemplo em arquivo √∫nico, assumimos que as depend√™ncias do CDN est√£o carregadas.
// =========================================================================================
const MediaPipeCDN = "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
const LandmarkerModel = `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float/1/pose_landmarker_lite.task`;

// @ts-ignore - Assumimos que o CDN injetou estas classes no escopo global (window)
const { FilesetResolver, PoseLandmarker } = window; 

// =========================================================================================
// 2. TIPAGENS E FUN√á√ïES AUXILIARES (L√≥gica de Neg√≥cio e UI)
// =========================================================================================

type PostureFeedback = {
  message: string;
  status: 'ideal' | 'warning' | 'error' | 'loading';
};

type TeleconsultaData = {
    id: string;
    patientName: string;
    patientAge: number;
};

/**
 * Simula a l√≥gica de an√°lise de postura baseada em coordenadas de landmarks.
 * @param landmarks As coordenadas da pose detectada pelo MediaPipe.
 */
const analyzePosture = (landmarks: any): PostureFeedback => { 
    if (!landmarks || landmarks.length === 0) {
        return { 
            message: "Aguardando detec√ß√£o de postura...", 
            status: 'loading' 
        };
    }

    // --- L√≥gica de detec√ß√£o de postura (simula√ß√£o por tempo) ---
    const now = new Date().getTime();
    if (now % 20000 < 5000) { 
        return { 
            message: "‚úÖ Posi√ß√£o Ideal! Rosto e tronco bem enquadrados.", 
            status: 'ideal' 
        };
    } else if (now % 20000 < 10000) {
        return { 
            message: "‚ö†Ô∏è Por favor, afaste-se um pouco mais para enquadrar o corpo superior.", 
            status: 'warning' 
        };
    } else if (now % 20000 < 15000) {
        return { 
            message: "‚ùå Postura Inadequada. Mantenha os ombros vis√≠veis e evite inclinar-se.", 
            status: 'error' 
        };
    } else {
        return { 
            message: "Analisando movimento e enquadramento...", 
            status: 'loading' 
        };
    }
};

// Componente para exibir o painel de feedback
const FeedbackPanel = ({ feedback, patientName }: { feedback: PostureFeedback, patientName: string }) => {
    let bgColor, borderColor, icon;
    
    switch (feedback.status) {
        case 'ideal':
            bgColor = 'bg-green-50';
            borderColor = 'border-green-500';
            icon = '‚úÖ';
            break;
        case 'warning':
            bgColor = 'bg-yellow-50';
            borderColor = 'border-yellow-500';
            icon = '‚ö†Ô∏è';
            break;
        case 'error':
            bgColor = 'bg-red-50';
            borderColor = 'border-red-500';
            icon = '‚ùå';
            break;
        case 'loading':
        default:
            bgColor = 'bg-blue-50';
            borderColor = 'border-blue-500';
            icon = 'üîÑ';
            break;
    }

    return (
        <div className={`p-6 rounded-xl shadow-xl border-l-4 ${bgColor} ${borderColor} h-full space-y-4`}>
            <h3 className="text-xl font-bold text-gray-800">Orienta√ß√µes de Postura</h3>
            <p className="text-sm text-gray-600">
                Ajuste sua posi√ß√£o na c√¢mera, {patientName}, para garantir que o m√©dico tenha a melhor visibilidade.
            </p>
            
            <div className={`p-4 rounded-lg font-semibold text-lg border transition-all duration-300
                ${feedback.status === 'ideal' ? 'bg-green-100 border-green-600 text-green-800' : 'bg-white border-gray-300 text-gray-700'}`}>
                {icon} {feedback.message}
            </div>

            <p className="text-xs text-gray-500 pt-2">O sistema monitora em tempo real a posi√ß√£o do seu corpo.</p>
        </div>
    );
};

// =========================================================================================
// 3. COMPONENTE PRINCIPAL (COM CORRE√á√ïES DE PERFORMANCE E EXIBI√á√ÉO)
// =========================================================================================

export function Teleconsulta() {
  const [teleconsulta, setTeleconsulta] = useState<TeleconsultaData | null>(null);
  const [feedback, setFeedback] = useState<PostureFeedback>({ message: "Iniciando c√¢mera...", status: 'loading' });
  const [isLandmarkerReady, setIsLandmarkerReady] = useState(false);

  const videoRef = useRef<HTMLVideoElement>(null); 
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationFrameRef = useRef<number | null>(null);
  const poseLandmarkerRef = useRef<any | null>(null);
  
  // CORRE√á√ÉO OOM: Flag para controlar o gargalo do MediaPipe
  // Impedindo que novas detec√ß√µes comecem antes que a anterior termine.
  const requestDetectRef = useRef(false); 

  
  /**
   * Fun√ß√£o para desenhar as landmarks no canvas (simula√ß√£o simplificada da DrawingUtils).
   * @param ctx O contexto 2D do canvas.
   * @param landmarks As landmarks de pose normalizadas.
   */
  const drawResults = useCallback((ctx: CanvasRenderingContext2D, landmarks: any[]) => {
    if (!ctx || !landmarks || landmarks.length === 0) return;
    
    // Configura√ß√µes de estilo
    ctx.strokeStyle = '#00FFFF'; // Ciano para os conectores
    ctx.fillStyle = '#FF00FF'; // Magenta para os pontos
    ctx.lineWidth = 3; 

    // Conex√µes de pose (simula√ß√£o dos principais ossos)
    const connections = [
        [11, 13], [13, 15], [12, 14], [14, 16], // Bra√ßos
        [11, 12], [23, 24], // Ombros
        [23, 25], [25, 27], [27, 29], // Perna Esquerda
        [24, 26], [26, 28], [28, 30] // Perna Direita
    ];

    // 1. Desenha as conex√µes
    ctx.beginPath();
    connections.forEach(([start, end]) => {
        if (landmarks[start] && landmarks[end]) {
            const startX = landmarks[start].x * ctx.canvas.width;
            const startY = landmarks[start].y * ctx.canvas.height;
            const endX = landmarks[end].x * ctx.canvas.width;
            const endY = landmarks[end].y * ctx.canvas.height;
            
            ctx.moveTo(startX, startY);
            ctx.lineTo(endX, endY);
        }
    });
    ctx.stroke();
    
    // 2. Desenha as landmarks
    landmarks.forEach((landmark) => {
        ctx.beginPath();
        ctx.arc(landmark.x * ctx.canvas.width, landmark.y * ctx.canvas.height, 4, 0, 2 * Math.PI);
        ctx.fill();
    });

  }, []);


  /**
   * Fun√ß√£o de loop de detec√ß√£o OTIMIZADA.
   * Soluciona o erro Out Of Memory (OOM) e a Tela Preta.
   */
  const detectPosture = useCallback((_timestamp: number) => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    const landmarker = poseLandmarkerRef.current;

    // Condi√ß√£o para CORRE√á√ÉO OOM: Se o Landmarker n√£o estiver pronto OU 
    // se o MediaPipe ainda estiver processando o frame anterior, pule a detec√ß√£o.
    if (!video || !canvas || !landmarker || requestDetectRef.current) {
        animationFrameRef.current = requestAnimationFrame(detectPosture);
        return;
    }

    const canvasCtx = canvas.getContext('2d');
    if (!canvasCtx) return;
    
    // Redimensiona o canvas para o tamanho do v√≠deo (melhora a exibi√ß√£o)
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // Define a flag de concorr√™ncia para TRUE.
    requestDetectRef.current = true;

    // 1. Chama a detec√ß√£o ass√≠ncrona do MediaPipe
    landmarker.detectForVideo(video, Date.now(), (result: any) => {
        // CORRE√á√ÉO OOM: O MediaPipe terminou de processar. Liberamos a flag.
        requestDetectRef.current = false; 

        // 2. CORRE√á√ÉO TELA PRETA: Limpa e Desenha o v√≠deo atual no Canvas
        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
        // Aplica o espelhamento horizontal no Canvas
        canvasCtx.scale(-1, 1);
        // Desenha o v√≠deo espelhado
        canvasCtx.drawImage(video, 0, 0, -canvas.width, canvas.height);
        canvasCtx.restore();

        let currentLandmarks = null;

        if (result.landmarks && result.landmarks.length > 0) {
            currentLandmarks = result.landmarks[0];
            
            // Desenha as landmarks sobre o v√≠deo no canvas
            drawResults(canvasCtx, currentLandmarks);
        } 
        
        // 3. Atualiza o feedback da postura
        const newFeedback = analyzePosture(currentLandmarks);
        setFeedback(newFeedback);

        // 4. Solicita o pr√≥ximo frame para continuar o loop de anima√ß√£o.
        animationFrameRef.current = requestAnimationFrame(detectPosture);
    });

  }, [drawResults]); 


  useEffect(() => {
    // Simula√ß√£o de carregamento de dados
    const fetchedData: TeleconsultaData = {
      id: 'simulated-id',
      patientName: "Jo√£o da Silva",
      patientAge: 75,
    };
    setTeleconsulta(fetchedData);
    
    // ==========================================================
    // 1. Inicializa o MediaPipe e o modelo
    // ==========================================================
    const initializeLandmarker = async () => {
        try {
            if (typeof FilesetResolver === 'undefined' || typeof PoseLandmarker === 'undefined') {
                 setFeedback({ message: "‚ùå Erro: Biblioteca MediaPipe n√£o carregada.", status: 'error' });
                return;
            }
            
            setFeedback({ message: "Carregando modelo de Pose...", status: 'loading' });

            const filesetResolver = await FilesetResolver.forVisionTasks(
                MediaPipeCDN + "/wasm"
            );
            
            const landmarker = await PoseLandmarker.createFromOptions(filesetResolver, {
              baseOptions: {
                modelAssetPath: LandmarkerModel,
                delegate: "GPU" 
              },
              runningMode: "VIDEO",
              numPoses: 1
            });
            
            poseLandmarkerRef.current = landmarker;
            setIsLandmarkerReady(true); // Landmarker pronto
            setFeedback({ message: "Modelo carregado, iniciando c√¢mera...", status: 'loading' });

        } catch (err) {
            console.error("Erro ao inicializar PoseLandmarker:", err);
            setFeedback({ 
                message: "‚ùå Erro: Falha ao carregar o modelo de Pose.", 
                status: 'error' 
            });
        }
    };
    initializeLandmarker();


    // ==========================================================
    // 2. Inicia a Webcam (Gatilho ap√≥s Landmarker estar pronto)
    // ==========================================================
    const startWebcam = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: {
                // OTIMIZA√á√ÉO: Diminui a resolu√ß√£o para reduzir o consumo de mem√≥ria (OOM)
                width: { ideal: 640 },
                height: { ideal: 480 },
            }, 
            audio: false // √Åudio desabilitado para simplificar, se n√£o for necess√°rio.
        });
        
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => {
            // S√≥ come√ßa o loop de detec√ß√£o quando o v√≠deo estiver carregado
            animationFrameRef.current = requestAnimationFrame(detectPosture); 
            setFeedback({ message: "Aguardando detec√ß√£o de postura...", status: 'loading' });
          };
        }
      } catch (err) {
        console.error("Erro ao acessar c√¢mera/microfone:", err);
        setFeedback({ 
          message: "‚ùå Erro: N√£o foi poss√≠vel acessar c√¢mera ou microfone.", 
          status: 'error' 
        });
      }
    };
    
    if(isLandmarkerReady) {
        startWebcam();
    }


  }, [isLandmarkerReady, detectPosture]); 


  // ==========================================================
  // 4. Fun√ß√£o de Cleanup (Garante a parada do loop e da c√¢mera)
  // ==========================================================
  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (videoRef.current && videoRef.current.srcObject) {
        (videoRef.current.srcObject as MediaStream).getTracks().forEach(track => track.stop());
      }
      if (poseLandmarkerRef.current && poseLandmarkerRef.current.close) {
        poseLandmarkerRef.current.close();
      }
    };
  }, []); 


  if (!teleconsulta) {
    return (
      <div className="text-center py-12">Carregando informa√ß√µes da teleconsulta...</div>
    );
  }

  const patientFirstName = teleconsulta.patientName.split(' ')[0] || "paciente";

  return (
    <div className="min-h-screen bg-gray-50 font-sans p-4 sm:p-6 lg:p-8">
      {/* Script do CDN para garantir o carregamento da biblioteca MediaPipe Task Library */}
      <script src={MediaPipeCDN + "/tasks-vision.js"}></script>
      
      <div className="max-w-7xl mx-auto">
          <h1 className="text-3xl font-extrabold text-indigo-800 text-center mb-8 border-b pb-4">
            Teleconsulta: {teleconsulta.patientName} ({teleconsulta.patientAge} anos)
          </h1>
      </div>

      <div className="flex flex-col lg:flex-row gap-8 max-w-7xl mx-auto h-[70vh]">
        
        {/* COLUNA 1: Canvas Vis√≠vel com o Stream e as Marca√ß√µes */}
        <div className="lg:flex-2 flex-1 bg-gray-800 rounded-2xl shadow-2xl relative overflow-hidden flex justify-center items-center">
          
          {/* O CANVAS √© a CORRE√á√ÉO para a tela preta, ele renderiza o v√≠deo + landmarks */}
          <canvas 
              ref={canvasRef} 
              className="rounded-2xl w-full h-full object-contain"
          ></canvas>
          
          {/* O V√çDEO fica OCULTO, servindo apenas como a fonte de dados (stream) para o Canvas */}
          <video 
              ref={videoRef} 
              autoPlay 
              playsInline 
              muted 
              className="hidden" 
          ></video>
          

          {/* Overlay de informa√ß√£o */}
          <div className="absolute bottom-4 left-4 p-2 px-4 bg-indigo-600 bg-opacity-80 text-white rounded-lg font-medium text-sm shadow-lg">
            <p>Sua Posi√ß√£o Monitorada</p>
          </div>
          
          {/* Feedback flutuante em caso de erro/loading */}
          {(feedback.status === 'error' || feedback.status === 'loading') && (
            <div className="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 p-4 bg-black bg-opacity-70 text-white rounded-lg text-center shadow-2xl">
                <p className="font-semibold">{feedback.message}</p>
            </div>
          )}
        </div>

        {/* COLUNA 2: Painel de Feedback e Orienta√ß√£o */}
        <div className="lg:flex-1 w-full lg:w-1/3">
          <FeedbackPanel 
              feedback={feedback} 
              patientName={patientFirstName}
          />
        </div>
      </div>
    </div>
  );
};